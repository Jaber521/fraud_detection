{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaber521/fraud_detection/blob/main/final_fraud_hybrid_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8da2f5bf",
      "metadata": {
        "id": "8da2f5bf"
      },
      "source": [
        "# üîç Mod√®le Hybride Final : Chargement ‚Üí Entra√Ænement ‚Üí √âvaluation ‚Üí Interface Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ea5c9f9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea5c9f9f",
        "outputId": "0fdfd821-376f-4b2f-f2c6-66a9a75372cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.0 (from gradio)\n",
            "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.9 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn tensorflow gradio joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ed071050",
      "metadata": {
        "id": "ed071050"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "import gradio as gr\n",
        "import traceback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7372e5f4",
      "metadata": {
        "id": "7372e5f4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Chargement des donn√©es enrichies\n",
        "df = pd.read_csv(\"/content/fraud_dataset_final_with_time_parts.csv\")\n",
        "\n",
        "# Extraction des colonnes temporelles\n",
        "\n",
        "df.drop(columns=[\"transaction_datetime\"], inplace=True, errors=\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b40b37ce",
      "metadata": {
        "id": "b40b37ce"
      },
      "outputs": [],
      "source": [
        "\n",
        "enc = {}\n",
        "for col in ['transaction_country', 'merchant_category_code', 'transaction_method', 'transaction_status']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "    enc[col] = le\n",
        "\n",
        "num_columns = [\n",
        "    'transaction_amount', 'average_amount_card', 'transaction_country',\n",
        "    'merchant_category_code', 'transaction_method', 'transaction_status',\n",
        "    'latitude', 'longitude', 'hour', 'minute', 'second',\n",
        "    'day', 'month', 'year', 'is_night'\n",
        "]\n",
        "sc = MinMaxScaler()\n",
        "df[num_columns] = sc.fit_transform(df[num_columns])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "591f3c79",
      "metadata": {
        "id": "591f3c79"
      },
      "outputs": [],
      "source": [
        "\n",
        "tx_counts = df['card_id'].value_counts()\n",
        "cards_lstm = tx_counts[tx_counts >= 2].index\n",
        "df_lstm = df[df['card_id'].isin(cards_lstm)]\n",
        "\n",
        "sequences, labels = [], []\n",
        "for _, group in df_lstm.groupby('card_id'):\n",
        "    group = group.sort_values(by=['hour', 'minute', 'second'])\n",
        "    sequences.append(group[num_columns].values)\n",
        "    labels.append(group['fraud_label'].values)\n",
        "\n",
        "X_lstm_train, X_lstm_test, y_lstm_train, y_lstm_test = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
        "X_lstm_train_pad = pad_sequences(X_lstm_train, padding='post')\n",
        "X_lstm_test_pad = pad_sequences(X_lstm_test, padding='post')\n",
        "y_lstm_train_pad = np.expand_dims(pad_sequences(y_lstm_train, padding='post'), -1)\n",
        "y_lstm_test_pad = np.expand_dims(pad_sequences(y_lstm_test, padding='post'), -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "71e3228a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71e3228a",
        "outputId": "6261f1d5-d17e-4121-e65c-881ad255f38e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.6507 - loss: 0.6903 - val_accuracy: 0.7542 - val_loss: 0.6791\n",
            "Epoch 2/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7759 - loss: 0.6689 - val_accuracy: 0.7542 - val_loss: 0.6758\n",
            "Epoch 3/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.7758 - loss: 0.6624 - val_accuracy: 0.7542 - val_loss: 0.6761\n",
            "Epoch 4/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.7714 - loss: 0.6553 - val_accuracy: 0.7542 - val_loss: 0.6681\n",
            "Epoch 5/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7756 - loss: 0.6544 - val_accuracy: 0.7542 - val_loss: 0.6626\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eb7f7b3db10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "model_lstm = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(None, X_lstm_train_pad.shape[2])),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_lstm.fit(X_lstm_train_pad, y_lstm_train_pad, epochs=5, batch_size=32, validation_split=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "589f591c",
      "metadata": {
        "id": "589f591c"
      },
      "outputs": [],
      "source": [
        "\n",
        "cards_rf = tx_counts[tx_counts < 2].index\n",
        "df_rf = df[df['card_id'].isin(cards_rf)]\n",
        "\n",
        "if len(df_rf) > 0:\n",
        "    X_rf = df_rf[num_columns]\n",
        "    y_rf = df_rf['fraud_label']\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_rf, y_rf)\n",
        "else:\n",
        "    rf_model = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9bdb8e5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bdb8e5d",
        "outputId": "6403437a-d306-4a8c-aa5a-cdbd394da35e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388ms/step\n",
            "LSTM:\n",
            "[[1451    0]\n",
            " [ 344    5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      1.00      0.89      1451\n",
            "           1       1.00      0.01      0.03       349\n",
            "\n",
            "    accuracy                           0.81      1800\n",
            "   macro avg       0.90      0.51      0.46      1800\n",
            "weighted avg       0.85      0.81      0.73      1800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# √âvaluation LSTM\n",
        "y_pred_lstm = (model_lstm.predict(X_lstm_test_pad) > 0.5).astype(int)\n",
        "print(\"LSTM:\")\n",
        "print(confusion_matrix(y_lstm_test_pad.flatten(), y_pred_lstm.flatten()))\n",
        "print(classification_report(y_lstm_test_pad.flatten(), y_pred_lstm.flatten()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5493b87e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5493b87e",
        "outputId": "ed51d6f7-2bbe-4aa6-b718-58d9a6949f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "\n",
        "model_lstm.save(\"lstm_fraud_model_v3.h5\")\n",
        "joblib.dump(sc, \"scaler_v3.pkl\")\n",
        "joblib.dump(enc, \"encoders_v3.pkl\")\n",
        "if rf_model: joblib.dump(rf_model, \"rf_model_v3.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "118fe954",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "118fe954",
        "outputId": "f7b91bf1-43f5-4336-f642-bcd9f21f36c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "enc = joblib.load(\"encoders_v3.pkl\")\n",
        "sc = joblib.load(\"scaler_v3.pkl\")\n",
        "lstm_model = load_model(\"lstm_fraud_model_v3.h5\")\n",
        "try:\n",
        "    rf_model = joblib.load(\"rf_model_v3.pkl\")\n",
        "except:\n",
        "    rf_model = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "de764aec",
      "metadata": {
        "id": "de764aec"
      },
      "outputs": [],
      "source": [
        "\n",
        "def predict_rf(transaction_amount, average_amount_card, transaction_country,\n",
        "               merchant_category_code, transaction_method, transaction_status,\n",
        "               hour, minute, second, day, month, year, latitude, longitude):\n",
        "    try:\n",
        "        is_night = 1 if 0 <= int(hour) < 7 else 0\n",
        "        merchant_category_code = str(merchant_category_code)\n",
        "        for col, val in zip(['transaction_country', 'merchant_category_code', 'transaction_method', 'transaction_status'],\n",
        "                            [transaction_country, merchant_category_code, transaction_method, transaction_status]):\n",
        "            if val not in enc[col].classes_:\n",
        "                return f\"‚ùå Valeur inconnue dans {col} : {val}\"\n",
        "        transaction_country = enc['transaction_country'].transform([transaction_country])[0]\n",
        "        merchant_category_code = enc['merchant_category_code'].transform([merchant_category_code])[0]\n",
        "        transaction_method = enc['transaction_method'].transform([transaction_method])[0]\n",
        "        transaction_status = enc['transaction_status'].transform([transaction_status])[0]\n",
        "        data = [[\n",
        "            transaction_amount, average_amount_card, transaction_country,\n",
        "            merchant_category_code, transaction_method, transaction_status,\n",
        "            latitude, longitude, hour, minute, second, day, month, year, is_night\n",
        "        ]]\n",
        "        scaled = sc.transform(data)\n",
        "        proba = rf_model.predict_proba(scaled)[0][1]\n",
        "        return f\"‚úÖ Proba fraude : {float(proba):.2f} ‚Üí {'FRAUDE' if proba > 0.5 else 'OK'}\"\n",
        "    except Exception:\n",
        "        return \"‚ùå Erreur RF :\\n\" + traceback.format_exc()\n",
        "\n",
        "def predict_lstm(df):\n",
        "    try:\n",
        "        df = df.copy()\n",
        "        df['merchant_category_code'] = df['merchant_category_code'].astype(str)\n",
        "        df['is_night'] = df['hour'].apply(lambda h: 1 if 0 <= int(h) < 7 else 0)\n",
        "        for col in ['transaction_country', 'merchant_category_code', 'transaction_method', 'transaction_status']:\n",
        "            if not all(df[col].isin(enc[col].classes_)):\n",
        "                return f\"‚ùå Valeur inconnue dans {col}\"\n",
        "            df[col] = enc[col].transform(df[col])\n",
        "        X = sc.transform(df[num_columns])\n",
        "        X_seq = np.expand_dims(X, axis=0)\n",
        "        preds = lstm_model.predict(X_seq)[0].flatten()\n",
        "        df['prob_fraude'] = preds\n",
        "        df['fraude'] = df['prob_fraude'].apply(lambda x: \"‚úÖ\" if x > 0.5 else \"üü¢\")\n",
        "        return df[['hour', 'minute', 'second', 'prob_fraude', 'fraude']]\n",
        "    except Exception:\n",
        "        return \"‚ùå Erreur LSTM :\\n\" + traceback.format_exc()\n",
        "\n",
        "def charger_csv_lstm(file):\n",
        "    try:\n",
        "        return pd.read_csv(file.name)\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Erreur : {e}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0faec759",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "0faec759",
        "outputId": "f70edf9d-ecb6-4ec3-feb4-a07bd8d79541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0edbda9bdff70e9430.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0edbda9bdff70e9430.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\n",
        "dropdown_vals = {col: enc[col].classes_.tolist() for col in enc}\n",
        "\n",
        "import gradio as gr\n",
        "example_df = pd.DataFrame({\n",
        "    \"transaction_amount\": [120.0],\n",
        "    \"average_amount_card\": [100.0],\n",
        "    \"transaction_country\": [\"France\"],\n",
        "    \"merchant_category_code\": [\"5411\"],\n",
        "    \"transaction_method\": [\"Online\"],\n",
        "    \"transaction_status\": [\"approved\"],\n",
        "    \"latitude\": [48.8566],\n",
        "    \"longitude\": [2.3522],\n",
        "    \"hour\": [13], \"minute\": [45], \"second\": [0],\n",
        "    \"day\": [1], \"month\": [5], \"year\": [2025]\n",
        "})\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# üîê D√©tection de Fraude - Mod√®le Hybride\")\n",
        "\n",
        "    mode = gr.Radio([\"Transaction isol√©e (RF)\", \"S√©quence (LSTM)\"], label=\"Mode\")\n",
        "\n",
        "    rf_inputs = [\n",
        "        gr.Number(label=\"Montant\"),\n",
        "        gr.Number(label=\"Moyenne\"),\n",
        "        gr.Dropdown(dropdown_vals['transaction_country'], label=\"Pays\"),\n",
        "        gr.Dropdown(dropdown_vals['merchant_category_code'], label=\"MCC\"),\n",
        "        gr.Dropdown(dropdown_vals['transaction_method'], label=\"M√©thode\"),\n",
        "        gr.Dropdown(dropdown_vals['transaction_status'], label=\"Statut\"),\n",
        "        gr.Number(label=\"Heure\"), gr.Number(label=\"Minute\"), gr.Number(label=\"Seconde\"),\n",
        "        gr.Number(label=\"Jour\"), gr.Number(label=\"Mois\"), gr.Number(label=\"Ann√©e\"),\n",
        "        gr.Number(label=\"Latitude\"), gr.Number(label=\"Longitude\")\n",
        "    ]\n",
        "\n",
        "    file_input = gr.File(label=\"üìÅ Charger CSV LSTM\", file_types=[\".csv\"])\n",
        "    df_input = gr.Dataframe(headers=example_df.columns.tolist(), row_count=(2, \"dynamic\"))\n",
        "    file_input.change(fn=charger_csv_lstm, inputs=file_input, outputs=df_input)\n",
        "\n",
        "    submit = gr.Button(\"Pr√©dire\")\n",
        "    output = gr.Dataframe()\n",
        "\n",
        "    def route(mode, *args):\n",
        "        return predict_rf(*args[:-1]) if mode == \"Transaction isol√©e (RF)\" else predict_lstm(args[-1])\n",
        "\n",
        "    submit.click(fn=route, inputs=[mode] + rf_inputs + [df_input], outputs=output)\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}